{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seminar - ML + SoC \n",
    "### Based on the training \"From Algorithm to Hardware: Machine Learning in Embedded Systems\"\n",
    "\n",
    "##### San Luis, Argentina - 2025\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Synthesis for Machine Learning (hls4ml)\n",
    "\n",
    "\n",
    "üí° **High-Level Synthesis for Machine Learning (hls4ml)**  is an open-source library that transforms machine learning models into hardware descriptions optimized for FPGA deployment.\n",
    "\n",
    "**Key Features of hls4ml:** \n",
    "\n",
    "- Converts models from Keras, TensorFlow, PyTorch, and ONNX into High-Level Synthesis (HLS) projects.\n",
    "\n",
    "- Utilizes tools like Xilinx Vitis HLS and Intel HLS Compiler to generate optimized C++ code for hardware implementation.\n",
    "\n",
    "- Enhances efficiency by reducing latency and power consumption, making it ideal for AI applications in edge computing.\n",
    "\n",
    "- Supports quantization and pruning techniques to shrink model size while maintaining accuracy.\n",
    "\n",
    "\n",
    "For further details:\n",
    "\n",
    "- GitHub: https://github.com/fastmachinelearning/hls4ml\n",
    "\n",
    "- Web site: https://fastmachinelearning.org/hls4ml/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from qkeras import *\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "import hls4ml\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path a Vitis HLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como paso inicial se debe especificar el directorio de instalaci√≥n de Vivado HLS o Vitis HLS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path donde se encuentra instalado Vitis HLS!! \n",
    "\n",
    "os.environ['PATH'] = '/tools/Xilinx/XilinxUnified_2022/Vitis_HLS/2022.2/bin:' + os.environ['PATH']\n",
    "\n",
    "# Para M√ÅQUINA VIRTUAL!\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vitis_HLS/2022.2/bin:' + os.environ['PATH']\n",
    "os.environ['PATH']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model (.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "model = load_model('models/mnistQAP.h5', custom_objects=co)\n",
    "    \n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight distribution\n",
    "\n",
    "weights = np.concatenate([w.flatten() for w in model.get_weights()])\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.hist(weights, bins=60, color='green', alpha=0.6)\n",
    "plt.xlabel(\"Weight Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Model MLP for MNIST - Weight Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high-Level Synthesis for Machine Learning (hls4ml )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hls configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=['Activation'])\n",
    "hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(rounding_mode='AP_RND')\n",
    "hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(saturation_mode='AP_SAT')\n",
    "\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "import plotting\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(hls_config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][layer]['Trace'] = True\n",
    "    hls_config['LayerName'][layer]['ReuseFactor'] = 16\n",
    "\n",
    "hls_config['LayerName']['fc1_input_input']['Precision'] = 'ap_fixed<16, 6>'   \n",
    "hls_config['LayerName']['sigmoid']['Strategy'] = 'Stable'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hls4ml with Vitis HLS as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = hls4ml.converters.create_config(backend='vitis')\n",
    "\n",
    "# cfg['IOType']     = 'io_stream'   # Must set this if using CNNs!\n",
    "cfg['HLSConfig']  = hls_config      # HLS configuraiton\n",
    "cfg['KerasModel'] = model           # Keras model to be converted\n",
    "cfg['OutputDir']  = 'hls4ml/'       # Project name\n",
    "cfg['Part'] = 'xc7z020clg484-1'     # PYNQ-Z1 or Zedboard: xc7z020clg484-1  ARTIX-7 xc7a35tcsg325-1  # MPSoC xczu4eg-sfvc784-2-e  xczu3eg-sfvc784-1-e\n",
    "\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardware synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False, export=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### San Luis, Argentina - 2025\n",
    "\n",
    "Romina Soledad Molina, Ph.D. - MLab/STI ICTP, Trieste, Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
